{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_equally_spaced_colors(k):\n",
    "    colors = []\n",
    "    step = 360 / k  # Equally spaced hue step\n",
    "\n",
    "    for i in range(k):\n",
    "        hue = i * step  # Equally spaced hue values\n",
    "        rgb = hsv_to_rgb(hue, 1, 1)  # Convert hue to RGB values\n",
    "        scaled_rgb = tuple(\n",
    "            int(val * 255) for val in rgb\n",
    "        )  # Scale RGB values to 0-255 range\n",
    "        colors.append(scaled_rgb)\n",
    "\n",
    "    return colors\n",
    "\n",
    "\n",
    "def hsv_to_rgb(h, s, v):\n",
    "    c = v * s\n",
    "    x = c * (1 - abs((h / 60) % 2 - 1))\n",
    "    m = v - c\n",
    "\n",
    "    if 0 <= h < 60:\n",
    "        rgb = (c, x, 0)\n",
    "    elif 60 <= h < 120:\n",
    "        rgb = (x, c, 0)\n",
    "    elif 120 <= h < 180:\n",
    "        rgb = (0, c, x)\n",
    "    elif 180 <= h < 240:\n",
    "        rgb = (0, x, c)\n",
    "    elif 240 <= h < 300:\n",
    "        rgb = (x, 0, c)\n",
    "    else:\n",
    "        rgb = (c, 0, x)\n",
    "\n",
    "    return tuple((val + m) for val in rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./forks_segmentation.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Images that already have segmentation masks\n",
    "for image in data[\"images\"]:\n",
    "    i = 0\n",
    "    for tag in  image['tags']:\n",
    "        if 'segmentation' in tag: \n",
    "            i+=1\n",
    "            if i == 1:\n",
    "                print(image['id'])\n",
    "    if i >= 1:\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract first image with segmentation mask\n",
    "for image in data[\"images\"]:\n",
    "    if image['id'] == \"648b7c226f177e0007432879\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in image['tags']:\n",
    "    if \"segmentation\" in tag:\n",
    "        print(len(tag['segmentation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"http://\" + image[\"url\"])\n",
    "img = Image.open(BytesIO(req.content)).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def generate_binary_mask(exterior_points, interior_points, image_size):\n",
    "    # Create a blank image\n",
    "    image = Image.new('L', image_size, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Draw the exterior contour\n",
    "    draw.polygon(exterior_points, outline=1, fill=1)\n",
    "\n",
    "    # Draw the interior contours\n",
    "    for interior_contour in interior_points:\n",
    "        draw.polygon(interior_contour, outline=0, fill=0)\n",
    "\n",
    "    # Convert the image to a binary mask (numpy array)\n",
    "    binary_mask = np.array(image)\n",
    "\n",
    "    return binary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask = np.zeros((img.size[1],img.size[0]))\n",
    "for tag in image['tags']:\n",
    "    if 'segmentation' in tag:\n",
    "        ext_points = tag['segmentation'][-1]['extPoints']\n",
    "        int_points = tag['segmentation'][-1]['intPoints']\n",
    "        int_points = [list(map(tuple,int)) for int in int_points]\n",
    "        ext_points = list(map(tuple,ext_points))\n",
    "        mask = generate_binary_mask(ext_points,int_points,img.size)\n",
    "        indices = np.where(mask == 1)\n",
    "        final_mask[indices] = 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_left_bottom_quarter_pil(image):\n",
    "    # Open the image using PIL\n",
    "    \n",
    "    # Get the size (width and height) of the image\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Crop the left bottom quarter of the image\n",
    "    cropped_image = image.crop((0, height // 2, width // 2, height))\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "def crop_left_bottom_quarter_numpy(mask_array):\n",
    "    # Get the shape (height, width) of the numpy mask array\n",
    "    height, width = mask_array.shape\n",
    "    \n",
    "    # Crop the left bottom quarter of the numpy array\n",
    "    cropped_array = mask_array[height // 2:, :width // 2]\n",
    "    \n",
    "    return cropped_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img = crop_left_bottom_quarter_pil(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask = crop_left_bottom_quarter_numpy(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seggpt_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_mask = crop_mask\n",
    "prompt_img = crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def split_image_into_grids(image, num_horizontal_cells, num_vertical_cells):\n",
    "    width, height = image.size\n",
    "    cell_width = width // num_horizontal_cells\n",
    "    cell_height = height // num_vertical_cells\n",
    "    grids = []\n",
    "    for y in range(0, num_vertical_cells):\n",
    "        for x in range(0, num_horizontal_cells):\n",
    "            grid_left = x * cell_width\n",
    "            grid_right = (x + 1) * cell_width\n",
    "            grid_top = y * cell_height\n",
    "            grid_bottom = (y + 1) * cell_height\n",
    "            \n",
    "            if x == num_horizontal_cells - 1:\n",
    "                grid_right = width\n",
    "                \n",
    "            if y == num_vertical_cells - 1:\n",
    "                grid_bottom = height\n",
    "\n",
    "            grid = image.crop((grid_left, grid_top, grid_right, grid_bottom))\n",
    "            grids.append((grid_left, grid_top, grid))\n",
    "    return grids\n",
    "\n",
    "def predict_instance_segmentation(predict, grids):\n",
    "    masks = []\n",
    "    for x, y, grid in grids:\n",
    "        mask,image = predict(grid)\n",
    "        masks.append((x, y, mask))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    return masks\n",
    "\n",
    "def stitch_masks(image_size, masks):\n",
    "    width, height = image_size\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for x, y, m in masks:\n",
    "        mask[y:y + m.shape[0], x:x + m.shape[1]] = m\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"http://\" + data[\"images\"][1][\"url\"])\n",
    "test_image = Image.open(BytesIO(req.content)).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask,out_image = seggpt_inference.predict(prompt_img,prompt_mask,test_image,threshold = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming you have a function `predict(image)` that predicts instance segmentation masks\n",
    "# and an image named `input_image` which is a PIL image.\n",
    "\n",
    "# Define the number of grid cells you want to split the image into (e.g., 3x3)\n",
    "num_horizontal_cells = 6\n",
    "num_vertical_cells = 6\n",
    "\n",
    "# Split the PIL image into grids\n",
    "grids = split_image_into_grids(test_image, num_horizontal_cells, num_vertical_cells)\n",
    "\n",
    "# Define the predict function (assuming it takes a PIL image and returns a numpy binary mask)\n",
    "def predict(test_image):\n",
    "    # Your prediction logic here, which should return a numpy binary mask\n",
    "    # For example, you can convert the PIL image to a numpy array and perform prediction\n",
    "    out_mask,out_image = seggpt_inference.predict(prompt_img,prompt_mask,test_image,threshold = 400)\n",
    "    return out_mask, out_image\n",
    "\n",
    "# Predict instance segmentation masks for each grid\n",
    "masks = predict_instance_segmentation(predict, grids)\n",
    "\n",
    "# Get the original image size\n",
    "image_size = test_image.size\n",
    "\n",
    "# Stitch the masks together to create one segmentation mask\n",
    "result_mask = stitch_masks(image_size, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask,out_image = seggpt_inference.predict(prompt_img,prompt_mask,test_image,threshold = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "def separate_masks(binary_mask, area_threshold):\n",
    "    # Label connected components in the binary mask\n",
    "    labeled_mask = label(binary_mask)\n",
    "    \n",
    "    # Get region properties of each connected component\n",
    "    regions = regionprops(labeled_mask)\n",
    "    \n",
    "    # Initialize an empty list to store individual masks\n",
    "    separate_masks = []\n",
    "    \n",
    "    # Iterate over each region and create a separate binary mask\n",
    "    for region in regions:\n",
    "        # Filter regions based on area threshold\n",
    "        if region.area >= area_threshold:\n",
    "            instance_mask = (labeled_mask == region.label).astype(np.uint8)\n",
    "            separate_masks.append(instance_mask)\n",
    "    \n",
    "    return separate_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = separate_masks(result_mask,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_masks(masks):\n",
    "    # Initialize an empty array to store the combined mask\n",
    "    combined_mask = np.zeros_like(masks[0])\n",
    "\n",
    "    # Assign unique instance IDs to each mask\n",
    "    for i, mask in enumerate(masks, start=1):\n",
    "        # Find the indices where the mask is True\n",
    "        indices = np.where(mask == 1)\n",
    "\n",
    "        # Assign the instance ID to those indices in the combined mask\n",
    "        combined_mask[indices] = i\n",
    "\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mask = combine_masks(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(combined_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_segmentation_mask(mask, image):\n",
    "    # Create a copy of the original image\n",
    "    overlay = np.array(image.copy())\n",
    "\n",
    "    # Apply the mask as a red overlay on the image\n",
    "    red_overlay = np.zeros_like(overlay)\n",
    "    red_overlay[..., 0] = mask * 255\n",
    "\n",
    "    # Blend the red overlay with the original image\n",
    "    blended = cv2.addWeighted(overlay, 0.7, red_overlay, 0.3, 0)\n",
    "    return blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def overlay_segmentation(image, mask):\n",
    "    # Convert the PIL image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    num_instances = len(np.unique(mask))\n",
    "    # Create a copy of the image array to draw on\n",
    "    overlay = image_array.copy()\n",
    "\n",
    "    # Define colors for each instance ID\n",
    "    colors = generate_equally_spaced_colors(num_instances)\n",
    "\n",
    "    # Draw each instance in a different color on the overlay image\n",
    "    for instance_id in np.unique(mask):\n",
    "        if instance_id == 0:\n",
    "            continue\n",
    "\n",
    "        # Create a binary mask for the current instance ID\n",
    "        instance_mask = np.where(mask == instance_id, 255, 0).astype(np.uint8)\n",
    "\n",
    "        # Find contours in the binary mask\n",
    "        contours, _ = cv2.findContours(instance_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw the contours on the overlay image\n",
    "        cv2.drawContours(overlay, contours, -1, colors[instance_id], thickness=cv2.FILLED)\n",
    "\n",
    "    # Blend the overlay image with the original image\n",
    "    blended_image = cv2.addWeighted(overlay, 0.5, image_array, 0.5, 0)\n",
    "\n",
    "    # Convert the blended image back to PIL format\n",
    "    blended_image_pil = Image.fromarray(blended_image)\n",
    "\n",
    "    return blended_image_pil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = overlay_segmentation(test_image,combined_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Now lets auto-annotate the rest of the images using the single prompt_img/mask\n",
    "# for image in data['images']:\n",
    "#     if image['id'] == \"64b7210228151f0007746978\": ##Don't predict your prompt_image\n",
    "#         continue \n",
    "#     req = requests.get(\"http://\" + image[\"url\"])\n",
    "#     test_image = Image.open(BytesIO(req.content)).convert(\"RGB\")\n",
    "#     out_mask,out_image = seggpt_inference.predict(prompt_img,prompt_mask,test_image,threshold = 20)\n",
    "#     mask_overlay = show_segmentation_mask(out_mask,test_image)\n",
    "#     plt.imshow(test_image)\n",
    "#     plt.show()\n",
    "#     plt.imshow(out_image)\n",
    "#     plt.show()\n",
    "#     plt.imshow(out_mask)\n",
    "#     plt.show()\n",
    "#     plt.imshow(mask_overlay)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now lets auto-annotate the rest of the images using the single prompt_img/mask\n",
    "for image in data['images']:\n",
    "    if image['id'] == \"64b865e5cbdfe70007a71bb7\": ##Don't predict your prompt_image\n",
    "        continue \n",
    "    if image[\"url\"].endswith(\"comundefined\"): ##Matroid Backend Saving Image error\n",
    "        continue\n",
    "    req = requests.get(\"http://\" + image[\"url\"])\n",
    "    test_image = Image.open(BytesIO(req.content)).convert(\"RGB\")\n",
    "    out_mask,out_image = seggpt_inference.predict(prompt_img,prompt_mask,test_image,threshold = 400)\n",
    "    masks = separate_masks(out_mask,30)\n",
    "    if len(masks) > 0:\n",
    "        combined_mask = combine_masks(masks)\n",
    "        mask_overlay = overlay_segmentation(test_image,combined_mask)\n",
    "    else:\n",
    "        mask_overlay = test_image\n",
    "    plt.imshow(test_image)\n",
    "    plt.show()\n",
    "    plt.imshow(out_image)\n",
    "    plt.show()\n",
    "    plt.imshow(out_mask)\n",
    "    plt.show()\n",
    "    plt.imshow(mask_overlay)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now lets auto-annotate the rest of the images using the single prompt_img/mask\n",
    "for image in data['images']:\n",
    "    if image['id'] == \"64b865e5cbdfe70007a71bb7\": ##Don't predict your prompt_image\n",
    "        continue \n",
    "    if image[\"url\"].endswith(\"comundefined\"): ##Matroid Backend Saving Image error\n",
    "        continue\n",
    "    req = requests.get(\"http://\" + image[\"url\"])\n",
    "    test_image = Image.open(BytesIO(req.content)).convert(\"RGB\")\n",
    "    \n",
    "    \n",
    "    num_horizontal_cells = 3\n",
    "    num_vertical_cells = 3\n",
    "\n",
    "    # Split the PIL image into grids\n",
    "    grids = split_image_into_grids(test_image, num_horizontal_cells, num_vertical_cells)\n",
    "\n",
    "\n",
    "    # Predict instance segmentation masks for each grid\n",
    "    masks = predict_instance_segmentation(predict, grids)\n",
    "\n",
    "    # Get the original image size\n",
    "    image_size = test_image.size    \n",
    "\n",
    "    # Stitch the masks together to create one segmentation mask\n",
    "    result_mask = stitch_masks(image_size, masks, num_horizontal_cells, num_vertical_cells)\n",
    "    masks = separate_masks(result_mask,30)\n",
    "    if len(masks) > 0:\n",
    "        combined_mask = combine_masks(masks)\n",
    "        mask_overlay = overlay_segmentation(test_image,combined_mask)\n",
    "    else:\n",
    "        mask_overlay = test_image\n",
    "    \n",
    "    plt.imshow(test_image)\n",
    "    plt.show()\n",
    "    # plt.imshow(out_image)\n",
    "    # plt.show()\n",
    "    plt.imshow(result_mask)\n",
    "    plt.show()\n",
    "    plt.imshow(mask_overlay)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_segmented_area(mask):\n",
    "    return np.sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Now lets auto-annotate the rest of the images using the single prompt_img/mask\n",
    "for image in data['images']:\n",
    "    if image['id'] == \"64b865e5cbdfe70007a71bb7\": ##Don't predict your prompt_image\n",
    "        continue \n",
    "    if image[\"url\"].endswith(\"comundefined\"): ##Matroid Backend Saving Image error\n",
    "        continue\n",
    "    req = requests.get(\"http://\" + image[\"url\"])\n",
    "    test_image = Image.open(BytesIO(req.content)).convert(\"RGB\")\n",
    "    \n",
    "    \n",
    "    num_horizontal_cells = 3\n",
    "    num_vertical_cells = 3\n",
    "\n",
    "    # Split the PIL image into grids\n",
    "    grids = split_image_into_grids(test_image, num_horizontal_cells, num_vertical_cells)\n",
    "\n",
    "\n",
    "    # Predict instance segmentation masks for each grid\n",
    "    masks = predict_instance_segmentation(predict, grids)\n",
    "\n",
    "    # Get the original image size\n",
    "    image_size = test_image.size    \n",
    "\n",
    "    # Stitch the masks together to create one segmentation mask\n",
    "    result_mask = stitch_masks(image_size, masks, num_horizontal_cells, num_vertical_cells)\n",
    "    out_mask,out_image = seggpt_inference.predict(prompt_img,prompt_mask,test_image,threshold = 400)\n",
    "    area_whole = total_segmented_area(out_mask)\n",
    "    area_grid = total_segmented_area(result_mask)\n",
    "    if area_whole > area_grid:\n",
    "        masks = separate_masks(out_mask,30)\n",
    "    else:\n",
    "        masks = separate_masks(result_mask,30)\n",
    "    if len(masks) > 0:\n",
    "        combined_mask = combine_masks(masks)\n",
    "        mask_overlay = overlay_segmentation(test_image,combined_mask)\n",
    "    else:\n",
    "        mask_overlay = test_image\n",
    "    \n",
    "    plt.imshow(test_image)\n",
    "    plt.show()\n",
    "    # plt.imshow(out_image)\n",
    "    # plt.show()\n",
    "    plt.imshow(result_mask)\n",
    "    plt.show()\n",
    "    plt.imshow(mask_overlay)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now lets auto-annotate the rest of the images using the single prompt_img/mask\n",
    "for image in data['images']:\n",
    "    if image['id'] == \"64b865e5cbdfe70007a71bb7\": ##Don't predict your prompt_image\n",
    "        continue \n",
    "    if image[\"url\"].endswith(\"comundefined\"): ##Matroid Backend Saving Image error\n",
    "        continue\n",
    "    req = requests.get(\"http://\" + image[\"url\"])\n",
    "    test_image = Image.open(BytesIO(req.content)).convert(\"RGB\")\n",
    "    \n",
    "    \n",
    "    num_horizontal_cells = 4\n",
    "    num_vertical_cells = 4\n",
    "\n",
    "    # Split the PIL image into grids\n",
    "    grids = split_image_into_grids(test_image, num_horizontal_cells, num_vertical_cells)\n",
    "\n",
    "\n",
    "    # Predict instance segmentation masks for each grid\n",
    "    masks = predict_instance_segmentation(predict, grids)\n",
    "\n",
    "    # Get the original image size\n",
    "    image_size = test_image.size    \n",
    "\n",
    "    # Stitch the masks together to create one segmentation mask\n",
    "    result_mask = stitch_masks(image_size, masks, num_horizontal_cells, num_vertical_cells)\n",
    "    masks = separate_masks(result_mask,30)\n",
    "    if len(masks) > 0:\n",
    "        combined_mask = combine_masks(masks)\n",
    "        mask_overlay = overlay_segmentation(test_image,combined_mask)\n",
    "    else:\n",
    "        mask_overlay = test_image\n",
    "    \n",
    "    plt.imshow(test_image)\n",
    "    plt.show()\n",
    "    # plt.imshow(out_image)\n",
    "    # plt.show()\n",
    "    plt.imshow(result_mask)\n",
    "    plt.show()\n",
    "    plt.imshow(mask_overlay)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SegGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
